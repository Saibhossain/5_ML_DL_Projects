{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "aXO-67YvriyL",
        "Z6JAV42bbS7L",
        "lzgDNi7BrCuu",
        "C98S-9-cWF6E"
      ],
      "authorship_tag": "ABX9TyPy9EU4LyJNKCvGc8Siv9M5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saibhossain/5_ML_DL_Projects/blob/main/ML_DL_Projects.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# âœ… Project 1: House Price Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "aXO-67YvriyL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ“Œ **Objective:** Predict house prices based on features like size, number of rooms, location, etc."
      ],
      "metadata": {
        "id": "m-LpBJEcrpua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Define the Problem**\n",
        "\n",
        "* Goal: Predict house prices (a continuous value â†’ Regression problem)\n",
        "* Use case: For a real estate website that shows price predictions when users input house details"
      ],
      "metadata": {
        "id": "Uqb8Vzxuryl3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##House Prices: Advanced Regression 'solution' file"
      ],
      "metadata": {
        "id": "DfiLxjAPbKv0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2:** Collect and Explore the Data.\n",
        "* Dataset: Use the classic Kaggle : [House Prices - Advanced Regression Techniques](https://www.kaggle.com/datasets/carlmcbrideellis/house-prices-advanced-regression-solution-file/data)"
      ],
      "metadata": {
        "id": "R_lPrnFNsALL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"carlmcbrideellis/house-prices-advanced-regression-solution-file\")\n",
        "for filename in os.listdir(path):\n",
        "    if filename.endswith(\".csv\"):\n",
        "        csv_path = os.path.join(path, filename)\n",
        "        break\n",
        "df = pd.read_csv(csv_path)\n",
        "df.head()\n",
        "print(df)\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "u4yfcE62t3U8",
        "outputId": "25877686-000c-4b9e-aac2-5fb1aa1dd6db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b689a8a44c2e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Download latest version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkagglehub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"carlmcbrideellis/house-prices-advanced-regression-solution-file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/datasets.py\u001b[0m in \u001b[0;36mdataset_download\u001b[0;34m(handle, path, force_download)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_dataset_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloading Dataset: {h.to_url()} ...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mEXTRA_CONSOLE_BLOCK\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_resolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/registry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimpl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/resolver.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, handle, path, force_download)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mSome\u001b[0m \u001b[0mcases\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mmight\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCompetition\u001b[0m \u001b[0mdatasource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAPI\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbased\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \"\"\"\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Note handles are immutable, so _resolve() could not have altered our reference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/http_resolver.py\u001b[0m in \u001b[0;36m_resolve\u001b[0;34m(self, h, path, force_download)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;31m# First, we download the archive.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mapi_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marchive_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0m_extract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/clients.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(self, path, out_file, resource_handle, cached_path, extract_auto_compressed_file)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \"\"\"\n\u001b[1;32m    174\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         with requests.get(\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_user_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1312\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA (Exploratory Data Analysis):\n",
        "\n",
        "* Check missing values\n",
        "* Describe distributions\n",
        "* Visualize important features"
      ],
      "metadata": {
        "id": "-s0zCR_jCUDX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zRaujkBrcxQ"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "A0KDMdlktowR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum().sort_values(ascending=False).head(10)"
      ],
      "metadata": {
        "id": "bG-9530Vuz5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3:** Data Cleaning and Preprocessing\n",
        "\n",
        "Handle missing values:"
      ],
      "metadata": {
        "id": "ClUwc65jC9qI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(\"SalePrice\", axis=1)\n",
        "y = df[\"SalePrice\"]"
      ],
      "metadata": {
        "id": "F7V6gcq7Xthi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"RÂ² Score:\", r2_score(y_test, y_pred))\n",
        "print(\"RMSE:\", mean_squared_error(y_test, y_pred))"
      ],
      "metadata": {
        "id": "j0ZSooU4CuXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.histplot(df[\"SalePrice\"], bins=30, kde=True)\n",
        "plt.title(\"House Prices\")"
      ],
      "metadata": {
        "id": "uz2R9QFxahKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\")\n"
      ],
      "metadata": {
        "id": "Ukw6MPbTaw4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Boston House Prices-Advanced Regression Techniques"
      ],
      "metadata": {
        "id": "Z6JAV42bbS7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"fedesoriano/the-boston-houseprice-data\")\n",
        "for filename in os.listdir(path):\n",
        "    if filename.endswith(\".csv\"):\n",
        "        csv_path = os.path.join(path, filename)\n",
        "        break\n",
        "df = pd.read_csv(csv_path)\n",
        "df.head()\n",
        "print(df)\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "XDg32zlObWe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "boston = fetch_openml(name=\"boston\", version=1, as_frame=True)\n",
        "df = boston.frame\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "ISdGdr_VbpEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())\n",
        "print(df.describe())\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.histplot(df[\"MEDV\"], bins=30, kde=True)\n",
        "plt.title(\"House Prices\")"
      ],
      "metadata": {
        "id": "zD1UPlB6eHIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\")"
      ],
      "metadata": {
        "id": "BGfpPxiXeLks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# X = df.drop(\"MEDV\", axis=1)\n",
        "# y = df[\"MEDV\"]\n",
        "\n",
        "X = np.array(df.drop(\"MEDV\", axis=1), dtype=float)\n",
        "y = np.array(df[\"MEDV\"], dtype=float)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "print(\"RÂ² Score:\", r2_score(y_test, y_pred))\n",
        "print(\"RMSE:\", mean_squared_error(y_test, y_pred))"
      ],
      "metadata": {
        "id": "6qpW1Kg4enoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "print(\"Random Forest RÂ²:\", r2_score(y_test, y_pred_rf))\n",
        "print(\"Random Forest RMSE:\", mean_squared_error(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "id": "EbLhOUbnkopj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GE1gZGtMks_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#âœ… Project 2: Customer Churn Prediction"
      ],
      "metadata": {
        "id": "lzgDNi7BrCuu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ“Œ Objective:\n",
        "Predict whether a customer will leave (churn) or stay, based on customer behavior and attributes."
      ],
      "metadata": {
        "id": "40oFwnKGrGmB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Telecom, SaaS, or subscription-based companies want to reduce churn using predictive analytics."
      ],
      "metadata": {
        "id": "ZWx2zG2IrW9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"rhonarosecortez/telco-customer-churn\")\n",
        "\n",
        "for filename in os.listdir(path):\n",
        "    if filename.endswith(\".csv\"):\n",
        "        csv_path = os.path.join(path, filename)\n",
        "        break\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "df.head()\n",
        "print(df)\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "sOGO5-uQrX84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "IMIVoxBKAoW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "dXFreC7FAqc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"ChurnScore\"].value_counts()"
      ],
      "metadata": {
        "id": "SiotOaR7AxLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.histplot(df[\"ChurnScore\"], bins=30, kde=True)\n",
        "plt.title(\"Churn Score\")"
      ],
      "metadata": {
        "id": "GsrxTQ0QBEc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(data=df, x=\"ChurnScore\")"
      ],
      "metadata": {
        "id": "lBGRl_QnBuXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3:** Preprocess the Data"
      ],
      "metadata": {
        "id": "q3Vja4gmCO05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Drop unimportant columns"
      ],
      "metadata": {
        "id": "Y9An3XnqESep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "now_df = df.drop([\"CustomerID\", \"ChurnReason\", \"ChurnCategory\", \"CustomerStatus\", \"Country\", \"State\", \"City\", \"ZipCode\"], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "Y9WuAgq4ByCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_df.shape)"
      ],
      "metadata": {
        "id": "R-hgveZfdCBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Convert **TotalCharger** to numeric :"
      ],
      "metadata": {
        "id": "Wh-WZr7oEYDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors='coerce')\n",
        "df[\"InternetType\"].fillna(\"Unknown\", inplace=True)\n",
        "df[\"Offer\"].fillna(\"None\", inplace=True)\n",
        "df.dropna(inplace=True)\n"
      ],
      "metadata": {
        "id": "zoduOq9lEgra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode target variable\n",
        "df[\"ChurnLabel\"] = df[\"ChurnLabel\"].map({\"Yes\": 1, \"No\": 0})"
      ],
      "metadata": {
        "id": "J-ePuXOeVTJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "categorical_cols.remove(\"Under30\")  # this is redundant with Age\n",
        "\n",
        "# Encode binary columns with LabelEncoder\n",
        "le = LabelEncoder()\n",
        "for col in categorical_cols:\n",
        "    if df[col].nunique() == 2:\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "    else:\n",
        "        df = pd.get_dummies(df, columns=[col], drop_first=True)\n",
        "\n",
        "# Drop \"Under30\" as it duplicates information\n",
        "df.drop(\"Under30\", axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "Rhxx11YkFDEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> step 4 : plit data"
      ],
      "metadata": {
        "id": "atJ6rvTeF8zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop(\"ChurnLabel\", axis=1)\n",
        "y = df[\"ChurnLabel\"]\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
      ],
      "metadata": {
        "id": "uH8rse_tF7AY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Train model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "sMAF6OOQHvpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_preds = rf.predict(X_test)\n",
        "\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_preds))\n"
      ],
      "metadata": {
        "id": "JZE18769kZYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# âœ… Project 3: Product Recommendation System"
      ],
      "metadata": {
        "id": "C98S-9-cWF6E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ¯ Objective:\n",
        "Build a recommendation engine that suggests products to users based on past behavior."
      ],
      "metadata": {
        "id": "DYMrCwLZWRyi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Skills:\n",
        "* User-Item Matrix\n",
        "* Collaborative Filtering (Memory-based or Matrix Factorization)\n",
        "* Surprise or Scikit-surprise library\n",
        "* Evaluation: RMSE"
      ],
      "metadata": {
        "id": "9uvt3SCiPLyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-surprise"
      ],
      "metadata": {
        "id": "f9WMnEXEWaFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.24.4"
      ],
      "metadata": {
        "id": "9HG6W7vBd8vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import SVD, Dataset, Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "\n",
        "#Load dataset\n",
        "data = Dataset.load_builtin('ml-100k')\n",
        "print(data)\n",
        "\n",
        "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "PMm9qLBcWpTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SVD()\n",
        "model.fit(trainset)"
      ],
      "metadata": {
        "id": "7_cmmIZoeR53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.test(testset)\n",
        "print(\"RMSE: \",accuracy.rmse(predictions))\n",
        "print(\"MAE: \",accuracy.mae(predictions))"
      ],
      "metadata": {
        "id": "C3kqOlyIeYCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uid = str(196)\n",
        "iid = str(302)\n",
        "pred = model.predict(uid, iid)\n",
        "print(f\"Predicted rating by User {uid} for Movie {iid}: {pred.est:.2f}\")"
      ],
      "metadata": {
        "id": "Cgly4wwbe3AS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top-N Recommendations for a User"
      ],
      "metadata": {
        "id": "0mVEFlL1fGyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Get top-N recommendations for all users\n",
        "from collections import defaultdict\n",
        "\n",
        "def get_top_n(predictions, n=5):\n",
        "    top_n = defaultdict(list)\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        top_n[uid].append((iid, est))\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_n[uid] = user_ratings[:n]\n",
        "    return top_n\n",
        "\n",
        "top_n = get_top_n(predictions, n=5)\n",
        "\n",
        "# ğŸ¯ Top 5 for User 196\n",
        "print(f\"\\nTop 5 movie recommendations for User 196:\")\n",
        "for movie_id, score in top_n[\"196\"]:\n",
        "    print(f\"Movie ID: {movie_id}, Predicted Rating: {score:.2f}\")\n"
      ],
      "metadata": {
        "id": "p_7q9e6cfIEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Content-Based Filtering (NLP on Reviews)"
      ],
      "metadata": {
        "id": "ANiSB8chfOHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Sample product descriptions\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "# Mock dataset of products\n",
        "df = pd.DataFrame({\n",
        "    'product_id': ['101', '102', '103', '104', '105'],\n",
        "    'title': ['Wireless Mouse', 'Gaming Keyboard', 'Noise Cancelling Headphones', 'USB-C Hub', 'Portable SSD'],\n",
        "    'description': [\n",
        "        \"Smooth wireless mouse with ergonomic design\",\n",
        "        \"Mechanical keyboard with RGB lighting\",\n",
        "        \"Headphones with active noise cancellation and deep bass\",\n",
        "        \"Multiport USB-C hub for Mac and Windows\",\n",
        "        \"Fast and durable SSD for file storage and transfer\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "# âœ… TF-IDF Vectorization\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(df['description'])\n",
        "\n",
        "# âœ… Cosine similarity\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# âœ… Recommendation function\n",
        "def recommend(title, cosine_sim=cosine_sim):\n",
        "    idx = df[df['title'] == title].index[0]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:4]\n",
        "    product_indices = [i[0] for i in sim_scores]\n",
        "    return df['title'].iloc[product_indices]\n",
        "\n",
        "# ğŸ¯ Recommend similar products\n",
        "print(\"\\nProducts similar to 'Gaming Keyboard':\")\n",
        "print(recommend('Gaming Keyboard'))\n"
      ],
      "metadata": {
        "id": "60nUMmmUfOWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# âœ… Project 4: Sentiment Analysis from Customer Reviews"
      ],
      "metadata": {
        "id": "5d0zg6pBpny7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ¯ E-commerce or service-based businesses want to automatically understand customer opinions from reviews to improve product offerings, support, and brand perception."
      ],
      "metadata": {
        "id": "RVre8G5L-gAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets scikit-learn --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjZyL626EEvB",
        "outputId": "5e4ac342-6974-4940-d437-96e483fc8f77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n"
      ],
      "metadata": {
        "id": "XT2ATLAoEINI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"mayaaboelkhier/amazon-reviews-multilingual-us-v1-00\")\n",
        "\n",
        "# Function to find the TSV file recursively in subdirectories\n",
        "def find_tsv_file(path):\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for file in files:\n",
        "            if file.endswith('.tsv'):\n",
        "                return os.path.join(root, file)\n",
        "    return None  # Return None if no TSV file is found\n",
        "\n",
        "# Find the TSV file\n",
        "tsv_path = find_tsv_file(path)\n",
        "\n",
        "# Read the TSV file if found\n",
        "if tsv_path:\n",
        "    df = pd.read_csv(tsv_path, delimiter='\\t', on_bad_lines='skip')  # Use delimiter='\\t' for TSV files\n",
        "    df.head()\n",
        "    print(df)\n",
        "    print(\"Path to dataset files:\", tsv_path)\n",
        "else:\n",
        "    print(\"No TSV file found in the downloaded dataset.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpPKfd6cYLYH",
        "outputId": "7fce911c-e7ba-4003-b248-3b779794596d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/mayaaboelkhier/amazon-reviews-multilingual-us-v1-00?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.38G/1.38G [00:19<00:00, 74.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        marketplace  customer_id       review_id  product_id  product_parent  \\\n",
            "0                US     53096384   R63J84G1LOX6R  1563890119       763187671   \n",
            "1                US     53096399  R1BALOA11Z06MT  1559947608       381720534   \n",
            "2                US     53096332  R1LLAY5W5PZUS4  0671701800       860650224   \n",
            "3                US     53096335  R3R9VTJ82FXECQ  0425132153       624269601   \n",
            "4                US     51747709  R1P5J3FNBWTFXY  0517122707       161411385   \n",
            "...             ...          ...             ...         ...             ...   \n",
            "6900881          US        52303  R16DAHIWNXFOYI  B00QW8TYWO       828652896   \n",
            "6900882          US       565563  R1DS6EBGAEJDB5  B00PSLQYWE       156264553   \n",
            "6900883          US       254421  R3HEHT8JUA33VW  B000FC1LOC       354573823   \n",
            "6900884          US       146004   RVK4I33L93536  B008T4HHWS       599809487   \n",
            "6900885          US       146004   RLKW9OJ9943DY  B00HY7VU60       592331046   \n",
            "\n",
            "                                          product_title  \\\n",
            "0            The Sandman Vol. 1: Preludes and Nocturnes   \n",
            "1                    The 22 Immutable Laws of Marketing   \n",
            "2                                               Contact   \n",
            "3                                            Good Omens   \n",
            "4                               A Confederacy of Dunces   \n",
            "...                                                 ...   \n",
            "6900881                                     Crossy Road   \n",
            "6900882                          Downton Abbey Season 5   \n",
            "6900883  My Sister's Keeper: A Novel (Wsp Readers Club)   \n",
            "6900884                                Scent of a Woman   \n",
            "6900885                       The White Queen, Season 1   \n",
            "\n",
            "               product_category  star_rating  helpful_votes  total_votes vine  \\\n",
            "0                         Books          4.0            0.0          1.0    N   \n",
            "1                         Books          4.0            0.0          0.0    N   \n",
            "2                         Books          5.0            1.0          2.0    N   \n",
            "3                         Books          5.0            0.0          0.0    N   \n",
            "4                         Books          5.0            0.0          0.0    N   \n",
            "...                         ...          ...            ...          ...  ...   \n",
            "6900881             Mobile_Apps          5.0            0.0          0.0    N   \n",
            "6900882  Digital_Video_Download          5.0            0.0          0.0    N   \n",
            "6900883  Digital_Ebook_Purchase          5.0            0.0          0.0    N   \n",
            "6900884  Digital_Video_Download          5.0            0.0          0.0    N   \n",
            "6900885  Digital_Video_Download          5.0            0.0          1.0    N   \n",
            "\n",
            "        verified_purchase                                    review_headline  \\\n",
            "0                       N                            ignore the review below   \n",
            "1                       N                                            awesome   \n",
            "2                       N                          Read the book. It's good.   \n",
            "3                       N   Funniest book ever written about the Anti-Christ   \n",
            "4                       N  A winner that didn't last. Only a mothers love...   \n",
            "...                   ...                                                ...   \n",
            "6900881                 Y                                         Five Stars   \n",
            "6900882                 Y                                         Five Stars   \n",
            "6900883                 N  and she has beautifully written and explored t...   \n",
            "6900884                 N                                         Like this!   \n",
            "6900885                 N                                    Wonderful show!   \n",
            "\n",
            "                                               review_body review_date  \n",
            "0        this is the first 8 issues of the series. it i...  1995-08-13  \n",
            "1        I've always been partial to immutable laws. Th...  1995-08-17  \n",
            "2        This is a book about first contact with aliens...  1995-08-30  \n",
            "3        This is quite possibly *the* funniest book I h...  1995-09-11  \n",
            "4        The story behind the book is almost better tha...  1995-10-17  \n",
            "...                                                    ...         ...  \n",
            "6900881                                      very fun game  2015-08-31  \n",
            "6900882                                              Great  2015-08-31  \n",
            "6900883  This is my first book from Jodi, and she has b...  2015-08-31  \n",
            "6900884                                        Good movie!  2015-08-31  \n",
            "6900885  Amazing show that runs close to history. Love ...  2015-08-31  \n",
            "\n",
            "[6900886 rows x 15 columns]\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/mayaaboelkhier/amazon-reviews-multilingual-us-v1-00/versions/1/amazon_reviews_multilingual_US_v1_00.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())\n",
        "print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkCmSNCuEgFz",
        "outputId": "38eadba1-3635-46ed-9a05-1f9f69e55151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6900886 entries, 0 to 6900885\n",
            "Data columns (total 15 columns):\n",
            " #   Column             Dtype  \n",
            "---  ------             -----  \n",
            " 0   marketplace        object \n",
            " 1   customer_id        int64  \n",
            " 2   review_id          object \n",
            " 3   product_id         object \n",
            " 4   product_parent     int64  \n",
            " 5   product_title      object \n",
            " 6   product_category   object \n",
            " 7   star_rating        float64\n",
            " 8   helpful_votes      float64\n",
            " 9   total_votes        float64\n",
            " 10  vine               object \n",
            " 11  verified_purchase  object \n",
            " 12  review_headline    object \n",
            " 13  review_body        object \n",
            " 14  review_date        object \n",
            "dtypes: float64(3), int64(2), object(10)\n",
            "memory usage: 789.7+ MB\n",
            "None\n",
            "        customer_id  product_parent   star_rating  helpful_votes   total_votes\n",
            "count  6.900886e+06    6.900886e+06  6.900885e+06   6.900885e+06  6.900885e+06\n",
            "mean   2.918797e+07    4.933005e+08  4.306591e+00   2.044545e+00  3.251676e+00\n",
            "std    1.565196e+07    2.861562e+08  1.146197e+00   3.184494e+01  3.633977e+01\n",
            "min    1.000100e+04    2.254720e+05  1.000000e+00   0.000000e+00  0.000000e+00\n",
            "25%    1.501694e+07    2.495109e+08  4.000000e+00   0.000000e+00  0.000000e+00\n",
            "50%    2.881076e+07    4.965205e+08  5.000000e+00   0.000000e+00  0.000000e+00\n",
            "75%    4.414300e+07    7.448221e+08  5.000000e+00   1.000000e+00  2.000000e+00\n",
            "max    5.309659e+07    9.999881e+08  5.000000e+00   2.755000e+04  2.872700e+04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map star rating to sentiment\n",
        "def map_sentiment(rating):\n",
        "    if rating <= 2:\n",
        "        return 0  # Negative\n",
        "    elif rating == 3:\n",
        "        return 1  # Neutral\n",
        "    else:\n",
        "        return 2  # Positive"
      ],
      "metadata": {
        "id": "vcrHsH_CEuJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['review_body', 'star_rating']].dropna()\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNCG1zo6HuGy",
        "outputId": "1a5e066c-bc02-42b9-eedb-2a7bdabc820c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         review_body  star_rating\n",
            "0  this is the first 8 issues of the series. it i...          4.0\n",
            "1  I've always been partial to immutable laws. Th...          4.0\n",
            "2  This is a book about first contact with aliens...          5.0\n",
            "3  This is quite possibly *the* funniest book I h...          5.0\n",
            "4  The story behind the book is almost better tha...          5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['review_body'].apply(lambda x: isinstance(x, str))]\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tY6ajiSIJp7",
        "outputId": "39bb6a51-bf87-45d9-9697-c78733e541c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         review_body  star_rating\n",
            "0  this is the first 8 issues of the series. it i...          4.0\n",
            "1  I've always been partial to immutable laws. Th...          4.0\n",
            "2  This is a book about first contact with aliens...          5.0\n",
            "3  This is quite possibly *the* funniest book I h...          5.0\n",
            "4  The story behind the book is almost better tha...          5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment'] = df['star_rating'].apply(map_sentiment)"
      ],
      "metadata": {
        "id": "MUxtuPLtIYMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check class distribution\n",
        "df['sentiment'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "s6lfdyIZIaLO",
        "outputId": "911539c6-303b-414b-b545-f6c5a0b61a80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "2    5682724\n",
              "0     683380\n",
              "1     534514\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5682724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>683380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>534514</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8ONBLgTpKWB",
        "outputId": "1587820a-63e9-43b0-a633-6aaabfb62bd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Tokenization\n"
      ],
      "metadata": {
        "id": "YjLjx29uId_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def tokenizer_function(example):\n",
        "  return tokenizer(example['review_body'], padding='max_length', truncation=True)\n",
        "\n",
        "from datasets import Dataset\n",
        "dataset = Dataset.from_pandas(df[['review_body', 'sentiment']])\n",
        "dataset = dataset.map(tokenizer_function, batched=True)\n",
        "dataset = dataset.rename_column('sentiment', 'labels')\n",
        "dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "\n",
        "train_test = dataset.train_test_split(test_size=0.2, seed=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "OW13HGXkIfFW",
        "outputId": "55e4fbcd-6aa5-4112-952c-11a4c5852b7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-a49a421a8346>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review_body'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Load BERT Model"
      ],
      "metadata": {
        "id": "3FCb-eCzKv2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)"
      ],
      "metadata": {
        "id": "ZMxVp4Lxn6W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Define Trainer"
      ],
      "metadata": {
        "id": "GDC_UJ-DK8VO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_test['train'],\n",
        "    eval_dataset=train_test['test'],\n",
        ")"
      ],
      "metadata": {
        "id": "mse0XyNXK7iH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Train the Model"
      ],
      "metadata": {
        "id": "XRfqc4EnLDoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "sT-mralMLKWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Step 7: Evaluate the Model"
      ],
      "metadata": {
        "id": "g7iZDydNMuDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds_output = trainer.predict(train_test['test'])\n",
        "y_pred = np.argmax(preds_output.predictions, axis=1)\n",
        "y_true = preds_output.label_ids\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Negative\", \"Neutral\", \"Positive\"]))"
      ],
      "metadata": {
        "id": "b7Xh8EIoLOrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Make Predictions on Custom Input"
      ],
      "metadata": {
        "id": "rD6D-M1sMysp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    outputs = model(**inputs)\n",
        "    probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "    label = torch.argmax(probs).item()\n",
        "    return [\"Negative\", \"Neutral\", \"Positive\"][label]\n",
        "\n",
        "# Test\n",
        "predict_sentiment(\"The product is amazing and works perfectly!\")"
      ],
      "metadata": {
        "id": "tUC8DRfKMzmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project 5: Object Detection for Inventory Management"
      ],
      "metadata": {
        "id": "f7IkUEQedF2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ¯ Project Overview\n",
        "Objective: Detect and count items (e.g., bottles, boxes, cans) on shelves for inventory automation.\n",
        "\n",
        "* Skills Used: Object detection, YOLOv5, PyTorch, OpenCV, annotation formats, inference\n",
        "\n",
        "* Client Use Case: Retail stores need to detect missing or misplaced items on shelves in real-time using CCTV or smartphone cameras."
      ],
      "metadata": {
        "id": "QSLgIg2edPQU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Setup Environment"
      ],
      "metadata": {
        "id": "dtEgTTLE2owe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone YOLOv5 repo\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "NvhGoKoZyxXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Mount Google Drive (Optional for Saving Model)"
      ],
      "metadata": {
        "id": "bHaHq_9V2x99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ya3g6pALyz8i",
        "outputId": "744819e1-7aac-4cc5-cfe7-1ccf9b3f0d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Upload Dataset from Kaggle"
      ],
      "metadata": {
        "id": "5o6KrXAb3MCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1 On your local machine, upload your Kaggle API key (kaggle.json) to Colab."
      ],
      "metadata": {
        "id": "LZQHG5xQ3S-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq642YUJ3Pyd",
        "outputId": "36531300-4ef6-409e-f4a6-44a557a2575b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d <your-kaggle-dataset-id>\n",
        "!unzip -q <dataset.zip> -d data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G8Gh1N76PqI",
        "outputId": "20e29154-ed45-4892-8af9-5a34a878c3d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 1: syntax error near unexpected token `newline'\n",
            "/bin/bash: -c: line 1: `kaggle datasets download -d <your-kaggle-dataset-id>'\n",
            "/bin/bash: line 1: dataset.zip: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2 Download dataset:"
      ],
      "metadata": {
        "id": "3CLDTXm33ZZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d andrewmvd/products-detection\n",
        "!unzip -q products-detection.zip -d ../products"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ISU4DoQ3dNl",
        "outputId": "431cd04e-0c10-49f9-cb78-0fc8b29b4edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/cli.py\", line 68, in main\n",
            "    out = args.func(**command_args)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/api/kaggle_api_extended.py\", line 1734, in dataset_download_cli\n",
            "    with self.build_kaggle_client() as kaggle:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/api/kaggle_api_extended.py\", line 688, in build_kaggle_client\n",
            "    username=self.config_values['username'],\n",
            "             ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "KeyError: 'username'\n",
            "unzip:  cannot find or open products-detection.zip, products-detection.zip.zip or products-detection.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 4: Check and Edit data.yaml (if needed)"
      ],
      "metadata": {
        "id": "S-_qc8lX3zaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train: data/products/images/train\n",
        "val: data/products/images/val\n",
        "\n",
        "nc: 5  # number of classes (update this)\n",
        "names: ['class1', 'class2', 'class3', 'class4', 'class5']"
      ],
      "metadata": {
        "id": "NQ2rQtpa33BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Train the Model"
      ],
      "metadata": {
        "id": "QgKEyCYz4Zdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 416 --batch 16 --epochs 30 --data data/products.yaml --weights yolov5s.pt --name products-detector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLkde_nf4d38",
        "outputId": "330f147d-9ab2-453d-9f07-b563120b2b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING âš ï¸ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "2025-05-11 10:39:03.157699: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746959943.194390   10159 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746959943.205990   10159 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=data/products.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=products-detector, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/train.py\", line 987, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/train.py\", line 657, in main\n",
            "    check_file(opt.data),\n",
            "    ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/yolov5/utils/general.py\", line 507, in check_file\n",
            "    assert len(files), f\"File not found: {file}\"  # assert file was found\n",
            "           ^^^^^^^^^^\n",
            "AssertionError: File not found: data/products.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 6: Inference on Test Images"
      ],
      "metadata": {
        "id": "A5E026_-4smP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights runs/train/products-detector/weights/best.pt --img 416 --conf 0.4 --source data/products/images/val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6WxjPKF4jUb",
        "outputId": "72e65826-933a-485a-e541-48f91acbfb45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/products-detector/weights/best.pt'], source=data/products/images/val, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.4, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_format=0, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ğŸš€ v7.0-418-ga493afe1 Python-3.11.12 torch-2.6.0+cu124 CPU\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/detect.py\", line 439, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/detect.py\", line 434, in main\n",
            "    run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/yolov5/detect.py\", line 167, in run\n",
            "    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/yolov5/models/common.py\", line 490, in __init__\n",
            "    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/yolov5/models/experimental.py\", line 99, in attempt_load\n",
            "    ckpt = torch.load(attempt_download(w), map_location=\"cpu\")  # load\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/utils/patches.py\", line 116, in torch_load\n",
            "    return _torch_load(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 1425, in load\n",
            "    with _open_file_like(f, \"rb\") as opened_file:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 751, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 732, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "                     ^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'runs/train/products-detector/weights/best.pt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7: Manual User Input for Real-Time Prediction"
      ],
      "metadata": {
        "id": "yZ5k9xK142xb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image(filename='runs/detect/exp/image.jpg'))  # Replace with actual file name\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "eLHM86mr44PI",
        "outputId": "d37e83df-0f23-4e06-f417-9860205e3479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'runs/detect/exp/image.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-1edd6259f2f1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'runs/detect/exp/image.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Replace with actual file name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[0m\u001b[1;32m   1232\u001b[0m                 metadata=metadata)\n\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1264\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runs/detect/exp/image.jpg'"
          ]
        }
      ]
    }
  ]
}